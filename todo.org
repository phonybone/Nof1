* Implement LinearPipeline
- replaced with Pipeline._run_cmds
- has list of run_cmds
- runs each, does checking for retcode, throws exceptions, etc

* Provenance
- Incorporate Pipeline/* into django as a new application
- Read up on project-independent django applications

* API Improvements
Currently, the process to create a new pipeline from scratch goes 
something like this: 
- Write a class for each command, derived from RunCmd, and implementing
  each of get_cmd(), get_args(), get_environ(), inputs(), and outputs()
- Write a class for each branch of the pipeline, derived from Pipeline, 
  and implementing run() and outputs().
- define a hosts.conf file, since Pipeline demands it (but doesn't actually use it).
  This means creating the hosts.conf file, too.
- provide a logging.conf file (this really should be included in the Pipeline package)
* Continuity Checks:
- Add a continuity check that makes sure of the following:
-- The execution graph is connected; 
-- Anything else?  Can't check that every output is consumed as an input, because there are "spinoffs";
   Can't check that every input is consumed
-- Possible to check that the run commands actually create what the say they're going to create,
   other than actually running the pipeline?  Not really.  The scripts themselves are not aware of the
   pipeline, so the pipeline software can't really query the scripts for info, especially the ones 
   written out of house.  So we have to manually check everything, for the moment, anyway.

* up-to-date: 
This can be fooled if an earlier run of a pipeline created an output file with the same name/path

  

